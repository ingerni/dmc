{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11994218-52a4-46ba-9195-06a1c18a740b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "table_name = \"sesion_11.gold.ventas\"\n",
    "\n",
    "def get_metrics(\n",
    "    table_name: str\n",
    ") -> Tuple[Dict[str, int], str]:\t\n",
    "    delta_table = DeltaTable.forName(spark, table_name)\n",
    "                                    \n",
    "    history_df = delta_table.history()\n",
    "\n",
    "    for row in history_df.collect():\n",
    "        #print(row.operation)\n",
    "        if row.operation in (\"MERGE\",\"WRITE\"):\n",
    "            raw_metrics = row.asDict().get(\"operationMetrics\",{})\n",
    "            \n",
    "            numeric_metrics = {}\n",
    "            for k,v in raw_metrics.items():\n",
    "            #print(f\"{k} : {v}\")\n",
    "                numeric_metrics[k] = int(v)\n",
    "                \n",
    "            return numeric_metrics, table_name\n",
    "    \n",
    "get_metrics(table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51e3ccd4-3dac-4506-bec7-5ee29023b084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ob_id BIGINT NOT NULL COMMENT 'Job id del workflow',\n",
    "  job_run_id BIGINT NOT NULL COMMENT 'Job run id del workflow',\n",
    "  task_run_id BIGINT NOT NULL COMMENT 'Task run id del workflow',\n",
    "  job_start_time TIMESTAMP NOT NULL COMMENT 'Fecha inicio del workflow',\n",
    "  job_end_time TIMESTAMP NOT NULL COMMENT 'Fecha fin del workflow',\n",
    "  job_duration_seconds BIGINT NOT NULL COMMENT 'DuraciÃ³n del workflow',\n",
    "  job_status STRING NOT NULL COMMENT 'Estado del workflow',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7361940c-eed1-41a4-b483-b46f7f7ad1d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def insert_metrics(\n",
    "    metrics_tuple: Tuple[Dict[str, int], str]\n",
    ") -> None:\n",
    "    metrics, table_name = metrics_tuple\n",
    "\n",
    "    job_id = 0\n",
    "    job_run = 0\n",
    "    task_run = 0\n",
    "    job_start_time = ''\n",
    "    \n",
    "    catalog, schema, table = table_name.split('.')\n",
    "\n",
    "    df_metrics = (\n",
    "        spark.createDataFrame([metrics])\n",
    "        .withColumn('job_id', lit(job_id))\n",
    "        .withColumn('job_run', lit(job_run))\n",
    "        .withColumn('task_run', lit(task_run))\n",
    "        .withColumn('job_start_time', lit(job_start_time).cast('timestamp')\n",
    "        .withColumn('job_end_time', current_timestamp())\n",
    "        .withColumn('job_duration_seconds', col('job_end_time').cast('long') - col('job_start_time').cast('long'))\n",
    "        .withColumn('file_byte', col(\"numTargetBytesAdded\"))\n",
    "        .withColumn('job_status', \n",
    "                    when(col(\"numTargetFilesAdded\") > 0, lit(\"success\"))\n",
    "                    .otherwise(lit(\"failed\")))\n",
    "        .withColumn('table', lit(table))\n",
    "        .withColumn('layer', lit(schema))\n",
    "        .withColumn('rows_in', col(\"numTargetRowsInserted\"))\n",
    "        .withColumn('rows_inserted', col(\"numTargetRowsInserted\"))\n",
    "        .withColumn('rows_updated', col(\"numTargetRowsUpdated\"))\n",
    "        .withColumn('rows_deleted', col(\"numTargetRowsDeleted\"))\n",
    "        .withColumn('merge_duration_seconds', col(\"executionTimeMs\")/lit(1000))\n",
    "        \n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-09-09 20_22_49",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
